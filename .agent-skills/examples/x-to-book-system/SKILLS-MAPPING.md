# Skills Mapping: X-to-Book System

This document provides a detailed mapping between the Agent Skills for Context Engineering and the design decisions in the X-to-Book system PRD.

## Skill: multi-agent-patterns

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Supervisor pattern | "The supervisor pattern places a central agent in control, delegating to specialists and synthesizing results." | Orchestrator agent coordinates Scraper, Analyzer, Synthesizer, Writer, Editor agents |
| Context isolation | "Sub-agents exist primarily to isolate context, not to anthropomorphize role division." | Each agent operates in clean context focused on its phase |
| Telephone game problem | "LangGraph benchmarks found supervisor architectures initially performed 50% worse due to the 'telephone game' problem where supervisors paraphrase sub-agent responses incorrectly." | Phase outputs stored in file system, not passed through Orchestrator for synthesis |
| File system coordination | "For complex tasks requiring shared state, agents read and write to persistent storage." | All inter-agent data flows through file system |
| Supervisor bottleneck mitigation | "Implement output schema constraints so workers return only distilled summaries." | Orchestrator receives phase summaries, never raw data |

### Pattern Selection Rationale

The skill describes three patterns:

1. **Supervisor/Orchestrator**: "When to use: Complex tasks with clear decomposition, tasks requiring coordination across domains."
2. **Peer-to-Peer/Swarm**: "When to use: Tasks requiring flexible exploration, tasks where rigid planning is counterproductive."
3. **Hierarchical**: "When to use: Large-scale projects with clear hierarchical structure."

**Selected**: Supervisor/Orchestrator

**Rationale**: Book production has clear sequential phases (scrape → analyze → synthesize → write → edit). Quality gates between phases require central coordination. Human oversight is important for content quality.

---

## Skill: context-fundamentals

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Context as finite resource | "Context must be treated as a finite resource with diminishing marginal returns." | Explicit token budgets per agent (Orchestrator 50k, Writer 80k, etc.) |
| Progressive disclosure | "Progressive disclosure manages context efficiently by loading information only as needed." | Book outline loads first; chapter content loads only when Writer works on that chapter |
| Attention budget | "Models develop attention patterns from training data distributions where shorter sequences predominate." | Context limits set conservatively below model maximums |
| Tool output volume | "Tool outputs comprise the majority of tokens in typical agent trajectories, with research showing observations can reach 83.9% of total context usage." | Tweet data processed separately, never enters main agent contexts |

### Context Budget Allocation

From skill: "Design with explicit context budgets in mind. Know the effective context limit for your model and task."

PRD implementation:

```yaml
context_limits:
  orchestrator: 50000   # Routing only, no raw data
  scraper: 20000        # One account at a time
  analyzer: 80000       # Pattern extraction
  synthesizer: 100000   # Cross-account synthesis
  writer: 80000         # Per-chapter drafting
  editor: 60000         # Per-chapter review
```

---

## Skill: memory-systems

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Vector store limitations | "Vector stores lose relationship information... cannot answer 'What products did customers who purchased Product Y also buy?'" | Selected knowledge graph for relationship queries between accounts |
| Temporal validity | "Temporal knowledge graphs add validity periods to facts. Each fact has a 'valid from' and optionally 'valid until' timestamp." | All relationships have temporal validity for tracking position evolution |
| Entity memory | "Entity memory specifically tracks information about entities to maintain consistency." | Account, Tweet, Theme, Book, Chapter entity types defined |

### Memory Architecture Decision

From skill: "Choose memory architecture based on requirements: Simple persistence needs → File-system memory; Semantic search needs → Vector RAG; Relationship reasoning needs → Knowledge graph; Temporal validity needs → Temporal knowledge graph."

**Query requirements identified**:
- "What has @account said about AI in the last 30 days?" → Temporal + entity filtering
- "Which accounts disagree on crypto?" → Relationship traversal
- "How has @account's position evolved?" → Temporal queries

**Selected**: Temporal Knowledge Graph

---

## Skill: context-optimization

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Observation masking | "Observation masking replaces verbose tool outputs with compact references." | Raw tweet data stored in file system, not passed through context |
| Compaction triggers | "Trigger compaction after significant memory accumulation, when retrieval returns too many outdated results." | 70% context utilization triggers compaction |
| KV-cache optimization | "Place stable elements first (system prompt, tool definitions), then frequently reused elements, then unique elements last." | Context ordering: system prompt → tools → account config → daily outline → current task |

### Optimization Strategy

From skill: "When to optimize: Context utilization exceeds 70%, Response quality degrades as conversations extend."

PRD implementation:
```python
COMPACTION_THRESHOLD = 0.7  # 70% context utilization

if context_utilization > COMPACTION_THRESHOLD:
    phase_outputs = compact_phase_outputs(phase_outputs)
```

From skill: "What to apply: Tool outputs dominate → observation masking"

PRD implementation: All raw tweet data (potentially 100k+ tokens/day) is masked by:
1. Scraper writes to file system
2. Analyzer reads from file system, produces summaries
3. Summaries (not raw data) flow to subsequent phases

---

## Skill: tool-design

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Consolidation principle | "If a human engineer cannot definitively say which tool should be used in a given situation, an agent cannot be expected to do better." | 3 consolidated tools instead of 15+ narrow tools |
| Description structure | "Effective tool descriptions answer four questions: What does the tool do? When should it be used? What inputs does it accept? What does it return?" | All tools have explicit usage triggers and error recovery |
| Response format options | "Implementing response format options gives agents control over verbosity." | Tools support "concise" and "detailed" format parameters |
| Error message design | "Error messages must be actionable. They must tell the agent what went wrong and how to correct it." | Errors include recovery guidance (RATE_LIMITED includes retry_after) |

### Tool Consolidation

From skill: "Instead of implementing list_users, list_events, and create_event, implement schedule_event that handles the full workflow internally."

PRD implementation:

**Before consolidation** (what we avoided):
- `fetch_timeline`
- `fetch_thread`
- `fetch_engagement`
- `search_tweets`
- `store_entity`
- `query_entities`
- `update_validity`
- etc.

**After consolidation**:
- `x_data_tool` - all X data operations
- `memory_tool` - all knowledge graph operations
- `writing_tool` - all content operations

---

## Skill: evaluation

### Concepts Applied

| Concept | Skill Reference | PRD Application |
|---------|-----------------|-----------------|
| Multi-dimensional rubrics | "Agent quality is not a single dimension. It includes factual accuracy, completeness, coherence, tool efficiency, and process quality." | 5 weighted dimensions: Source Accuracy, Thematic Coherence, Completeness, Insight Quality, Readability |
| LLM-as-judge | "LLM-based evaluation scales to large test sets and provides consistent judgments." | Automated evaluation for coherence and insight quality |
| Human evaluation | "Human evaluation catches what automation misses." | Trigger human review when score < 0.7 or source accuracy < 0.8 |
| Outcome-focused evaluation | "The solution is outcome-focused evaluation that judges whether agents achieve right outcomes while following reasonable processes." | Evaluate final book quality, not intermediate steps |

### Evaluation Rubric

From skill: "Effective rubrics cover key dimensions with descriptive levels."

PRD implementation:

| Dimension | Weight | Measurement |
|-----------|--------|-------------|
| Source Accuracy | 30% | Automated quote verification against original tweets |
| Thematic Coherence | 25% | LLM-as-judge for narrative flow |
| Completeness | 20% | Theme coverage calculation |
| Insight Quality | 15% | LLM-as-judge for synthesis beyond restating |
| Readability | 10% | Automated metrics + LLM judge |

---

## Cross-Skill Integration

The skills are designed to work together. This example demonstrates integration patterns:

| Integration | Skills Combined | Application |
|-------------|-----------------|-------------|
| Agent context budgets | multi-agent-patterns + context-fundamentals | Each agent has explicit limits based on role |
| File system coordination | multi-agent-patterns + context-optimization | Avoids context passing, enables masking |
| Memory-aware synthesis | memory-systems + context-optimization | Query relevant facts without loading full history |
| Quality-driven routing | evaluation + multi-agent-patterns | Orchestrator uses quality scores for phase gates |

This integration is the core value proposition of the skills collection: they provide complementary patterns that address different aspects of context engineering while working together cohesively.

